{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project1-A2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Because of problems with the dependencies the first part of the project continues here."
      ],
      "metadata": {
        "id": "xSQ_esoIK21Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MGEdVoxqUvX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "LG4Hmpx_LYaG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next code does the first things we need to prepare the dataset and is described in the first part."
      ],
      "metadata": {
        "id": "BdQsNxnRL-kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heartArray = np.loadtxt('heart.dat', unpack = True)\n",
        "columns = ['age ','sex','cpt', 'rbp', 'sc', 'fbs', \n",
        "                                         'rer', 'mhr', 'eia', 'oldpeak', 'slope', \n",
        "                                         'nmv', 'thal', 'presence']\n",
        "df = pd.DataFrame(heartArray.transpose(1, 0), columns = columns)\n",
        "\n",
        "dfx = df.drop(columns=[\"fbs\"])\n",
        "\n",
        "y = dfx[\"presence\"].values\n",
        "\n",
        "y[y == 1] = 0\n",
        "y[y == 2] = 1\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dfx.drop(columns=[\"presence\"]).values, \n",
        "                                                    dfx[\"presence\"].values, test_size=0.3, \n",
        "                                                    random_state=0)\n"
      ],
      "metadata": {
        "id": "kQKq9OJjL-On"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['Random Forest', 'Linear SVM','Naive Bayes']\n",
        "classifiers = [RandomForestClassifier(n_estimators=100, random_state=0), \n",
        "               SVC(kernel='linear', C=10),\n",
        "               GaussianNB()]"
      ],
      "metadata": {
        "id": "_LBTl83oTYJI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rebalancing**"
      ],
      "metadata": {
        "id": "uixLSXKGMcBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cost matrix"
      ],
      "metadata": {
        "id": "oRgSAqMcMZIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost_matrix = [[0 , 1], [5, 0]]"
      ],
      "metadata": {
        "id": "RIzllPOKMlRb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Current samples"
      ],
      "metadata": {
        "id": "5OOtQPuDMof4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqTmfSlhMo72",
        "outputId": "9e14544b-1b4d-494d-be84-851561c14a52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0.0: 102, 1.0: 87})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Undersampling*"
      ],
      "metadata": {
        "id": "c2h-aYElNA3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = RandomUnderSampler(sampling_strategy={0: 74, 1: 87}, random_state=1)\n",
        "X_train_us, y_train_us = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_train_us))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XanehPoPM7-D",
        "outputId": "ca8ab827-fdd7-4ac7-9e4e-723ddfacb339"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1.0: 87, 0.0: 74})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "  print(\"\\033[4m\" +  name + \"\\033[0m\")\n",
        "  print(\"------------------------------------------------------\")\n",
        "\n",
        "  clf.fit(X_train_us, y_train_us)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['absence','presence']))\n",
        "\n",
        "  conf_m = confusion_matrix(y_test, y_pred)\n",
        "  print(\"\\033[4m\" + \"Confusion matrix\" + \"\\033[0m\")\n",
        "  print(conf_m , \"\\n\") \n",
        "  loss = np.sum(conf_m * cost_matrix)\n",
        "  print(\"loss: %d\" %loss)\n",
        "  print(\"------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "id": "fdRD03D4UUpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a92039b-ca14-4e2b-9e7a-59c4b9ca6c9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[4mRandom Forest\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.89      0.71      0.79        48\n",
            "    presence       0.67      0.88      0.76        33\n",
            "\n",
            "    accuracy                           0.78        81\n",
            "   macro avg       0.78      0.79      0.78        81\n",
            "weighted avg       0.80      0.78      0.78        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[34 14]\n",
            " [ 4 29]] \n",
            "\n",
            "loss: 34\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mLinear SVM\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.89      0.71      0.79        48\n",
            "    presence       0.67      0.88      0.76        33\n",
            "\n",
            "    accuracy                           0.78        81\n",
            "   macro avg       0.78      0.79      0.78        81\n",
            "weighted avg       0.80      0.78      0.78        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[34 14]\n",
            " [ 4 29]] \n",
            "\n",
            "loss: 34\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mNaive Bayes\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.86      0.79      0.83        48\n",
            "    presence       0.73      0.82      0.77        33\n",
            "\n",
            "    accuracy                           0.80        81\n",
            "   macro avg       0.80      0.80      0.80        81\n",
            "weighted avg       0.81      0.80      0.80        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[38 10]\n",
            " [ 6 27]] \n",
            "\n",
            "loss: 40\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use different undersampling strategy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ku4wrP4jSuya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = RandomUnderSampler(sampling_strategy={0: 43, 1: 87}, random_state=1)\n",
        "X_train_us, y_train_us = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_train_us))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vzxxEKaS0-E",
        "outputId": "26dbf07a-b57c-4f17-c02f-5e10aeb3b73a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1.0: 87, 0.0: 43})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "  print(\"\\033[4m\" +  name + \"\\033[0m\")\n",
        "  print(\"------------------------------------------------------\")\n",
        "\n",
        "  clf.fit(X_train_us, y_train_us)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['absence','presence']))\n",
        "\n",
        "  conf_m = confusion_matrix(y_test, y_pred)\n",
        "  print(\"\\033[4m\" + \"Confusion matrix\" + \"\\033[0m\")\n",
        "  print(conf_m , \"\\n\") \n",
        "  loss = np.sum(conf_m * cost_matrix)\n",
        "  print(\"loss: %d\" %loss)\n",
        "  print(\"------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdlrpaMVS5vm",
        "outputId": "11761835-874f-422a-e996-0975eaed0027"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[4mRandom Forest\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.90      0.54      0.68        48\n",
            "    presence       0.58      0.91      0.71        33\n",
            "\n",
            "    accuracy                           0.69        81\n",
            "   macro avg       0.74      0.73      0.69        81\n",
            "weighted avg       0.77      0.69      0.69        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[26 22]\n",
            " [ 3 30]] \n",
            "\n",
            "loss: 37\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mLinear SVM\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.92      0.69      0.79        48\n",
            "    presence       0.67      0.91      0.77        33\n",
            "\n",
            "    accuracy                           0.78        81\n",
            "   macro avg       0.79      0.80      0.78        81\n",
            "weighted avg       0.81      0.78      0.78        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[33 15]\n",
            " [ 3 30]] \n",
            "\n",
            "loss: 30\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mNaive Bayes\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.85      0.71      0.77        48\n",
            "    presence       0.66      0.82      0.73        33\n",
            "\n",
            "    accuracy                           0.75        81\n",
            "   macro avg       0.75      0.76      0.75        81\n",
            "weighted avg       0.77      0.75      0.76        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[34 14]\n",
            " [ 6 27]] \n",
            "\n",
            "loss: 44\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oversampling**"
      ],
      "metadata": {
        "id": "L4pzxQihTf2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = RandomOverSampler(sampling_strategy={0: 102, 1: 100}, random_state=1)\n",
        "X_train_us, y_train_us = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_train_us))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGIC2OYWThQP",
        "outputId": "8d3a8798-e2ca-4202-a0da-7065bf044eeb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0.0: 102, 1.0: 100})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "  print(\"\\033[4m\" +  name + \"\\033[0m\")\n",
        "  print(\"------------------------------------------------------\")\n",
        "\n",
        "  clf.fit(X_train_us, y_train_us)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['absence','presence']))\n",
        "\n",
        "  conf_m = confusion_matrix(y_test, y_pred)\n",
        "  print(\"\\033[4m\" + \"Confusion matrix\" + \"\\033[0m\")\n",
        "  print(conf_m , \"\\n\") \n",
        "  loss = np.sum(conf_m * cost_matrix)\n",
        "  print(\"loss: %d\" %loss)\n",
        "  print(\"------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "117mx2glTwDX",
        "outputId": "89884411-9495-4790-8363-6fea76ed8195"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[4mRandom Forest\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.88      0.75      0.81        48\n",
            "    presence       0.70      0.85      0.77        33\n",
            "\n",
            "    accuracy                           0.79        81\n",
            "   macro avg       0.79      0.80      0.79        81\n",
            "weighted avg       0.81      0.79      0.79        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[36 12]\n",
            " [ 5 28]] \n",
            "\n",
            "loss: 37\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mLinear SVM\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.87      0.81      0.84        48\n",
            "    presence       0.75      0.82      0.78        33\n",
            "\n",
            "    accuracy                           0.81        81\n",
            "   macro avg       0.81      0.82      0.81        81\n",
            "weighted avg       0.82      0.81      0.82        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[39  9]\n",
            " [ 6 27]] \n",
            "\n",
            "loss: 39\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mNaive Bayes\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.84      0.79      0.82        48\n",
            "    presence       0.72      0.79      0.75        33\n",
            "\n",
            "    accuracy                           0.79        81\n",
            "   macro avg       0.78      0.79      0.79        81\n",
            "weighted avg       0.79      0.79      0.79        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[38 10]\n",
            " [ 7 26]] \n",
            "\n",
            "loss: 45\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use different oversampling strategy\n"
      ],
      "metadata": {
        "id": "JOxWsy5xT1-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = RandomOverSampler(sampling_strategy={0: 102, 1: 148}, random_state=1)\n",
        "X_train_us, y_train_us = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_train_us))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWNVZHUeT4FR",
        "outputId": "83b44612-78f4-416b-db37-f353bb7d8f4a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1.0: 148, 0.0: 102})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (148) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 102)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "  print(\"\\033[4m\" +  name + \"\\033[0m\")\n",
        "  print(\"------------------------------------------------------\")\n",
        "\n",
        "  clf.fit(X_train_us, y_train_us)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['absence','presence']))\n",
        "\n",
        "  conf_m = confusion_matrix(y_test, y_pred)\n",
        "  print(\"\\033[4m\" + \"Confusion matrix\" + \"\\033[0m\")\n",
        "  print(conf_m , \"\\n\") \n",
        "  loss = np.sum(conf_m * cost_matrix)\n",
        "  print(\"loss: %d\" %loss)\n",
        "  print(\"------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-f2K_TfUAVv",
        "outputId": "3fae581c-4416-4f65-cb74-048038b7dfe4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[4mRandom Forest\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.85      0.73      0.79        48\n",
            "    presence       0.68      0.82      0.74        33\n",
            "\n",
            "    accuracy                           0.77        81\n",
            "   macro avg       0.76      0.77      0.76        81\n",
            "weighted avg       0.78      0.77      0.77        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[35 13]\n",
            " [ 6 27]] \n",
            "\n",
            "loss: 43\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mLinear SVM\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.87      0.71      0.78        48\n",
            "    presence       0.67      0.85      0.75        33\n",
            "\n",
            "    accuracy                           0.77        81\n",
            "   macro avg       0.77      0.78      0.76        81\n",
            "weighted avg       0.79      0.77      0.77        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[34 14]\n",
            " [ 5 28]] \n",
            "\n",
            "loss: 39\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mNaive Bayes\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.86      0.79      0.83        48\n",
            "    presence       0.73      0.82      0.77        33\n",
            "\n",
            "    accuracy                           0.80        81\n",
            "   macro avg       0.80      0.80      0.80        81\n",
            "weighted avg       0.81      0.80      0.80        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[38 10]\n",
            " [ 6 27]] \n",
            "\n",
            "loss: 40\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compination**"
      ],
      "metadata": {
        "id": "L-LgKwN8UNDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = RandomUnderSampler(sampling_strategy={0: 90, 1: 87}, random_state=1)\n",
        "X_train_us, y_train_us = sampler.fit_resample(X_train, y_train)\n",
        "sampler = RandomOverSampler(sampling_strategy={0: 90, 1: 110}, random_state=1)\n",
        "X_train_us, y_train_us = sampler.fit_resample(X_train_us, y_train_us)\n",
        "print(Counter(y_train_us))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW_7k37OUPVO",
        "outputId": "c45dad16-e598-4ad1-8b04-7647a0fa41ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1.0: 110, 0.0: 90})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (110) in class 1 will be larger than the number of samples in the majority class (class #0.0 -> 90)\n",
            "  f\"After over-sampling, the number of samples ({n_samples})\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "  print(\"\\033[4m\" +  name + \"\\033[0m\")\n",
        "  print(\"------------------------------------------------------\")\n",
        "\n",
        "  clf.fit(X_train_us, y_train_us)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['absence','presence']))\n",
        "\n",
        "  conf_m = confusion_matrix(y_test, y_pred)\n",
        "  print(\"\\033[4m\" + \"Confusion matrix\" + \"\\033[0m\")\n",
        "  print(conf_m , \"\\n\") \n",
        "  loss = np.sum(conf_m * cost_matrix)\n",
        "  print(\"loss: %d\" %loss)\n",
        "  print(\"------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB3rt-K1Ux7c",
        "outputId": "70e67b02-bf0b-4531-c1fa-9ec7231efcb2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[4mRandom Forest\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.88      0.77      0.82        48\n",
            "    presence       0.72      0.85      0.78        33\n",
            "\n",
            "    accuracy                           0.80        81\n",
            "   macro avg       0.80      0.81      0.80        81\n",
            "weighted avg       0.81      0.80      0.80        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[37 11]\n",
            " [ 5 28]] \n",
            "\n",
            "loss: 36\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mLinear SVM\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.91      0.60      0.72        48\n",
            "    presence       0.61      0.91      0.73        33\n",
            "\n",
            "    accuracy                           0.73        81\n",
            "   macro avg       0.76      0.76      0.73        81\n",
            "weighted avg       0.79      0.73      0.73        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[29 19]\n",
            " [ 3 30]] \n",
            "\n",
            "loss: 34\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mNaive Bayes\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.84      0.77      0.80        48\n",
            "    presence       0.70      0.79      0.74        33\n",
            "\n",
            "    accuracy                           0.78        81\n",
            "   macro avg       0.77      0.78      0.77        81\n",
            "weighted avg       0.78      0.78      0.78        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[37 11]\n",
            " [ 7 26]] \n",
            "\n",
            "loss: 46\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected the rebalancing methods did not work that well because the data were already almost balanced"
      ],
      "metadata": {
        "id": "Zxejik4AU0Sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With weights**"
      ],
      "metadata": {
        "id": "sgP7-O4NeoVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['Random Forest', 'Linear SVM','Naive Bayes']\n",
        "classifiers = [RandomForestClassifier(n_estimators=100, random_state=0, class_weight={0: 10, 1: 13}), \n",
        "               SVC(kernel='linear', C=10,class_weight={0: 7, 1: 12}),\n",
        "               GaussianNB()]\n",
        "naiveBayesWeights = np.zeros(y_train.shape[0])\n",
        "naiveBayesWeights[np.where(y_train == 1)] = 5;\n",
        "naiveBayesWeights[np.where(y_train == 0)] = 3;"
      ],
      "metadata": {
        "id": "5efBYIFIfHHB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "  print(\"\\033[4m\" +  name + \"\\033[0m\")\n",
        "  print(\"------------------------------------------------------\")\n",
        "\n",
        "  if(name == 'Naive Bayes'):\n",
        "    clf.fit(X_train, y_train, naiveBayesWeights)\n",
        "  else:\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['absence','presence']))\n",
        "\n",
        "  conf_m = confusion_matrix(y_test, y_pred)\n",
        "  print(\"\\033[4m\" + \"Confusion matrix\" + \"\\033[0m\")\n",
        "  print(conf_m , \"\\n\") \n",
        "  loss = np.sum(conf_m * cost_matrix)\n",
        "  print(\"loss: %d\" %loss)\n",
        "  print(\"------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XurjP4J2e1nB",
        "outputId": "d0fce7de-5b9d-4421-c244-a455a1ad3358"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[4mRandom Forest\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.88      0.79      0.84        48\n",
            "    presence       0.74      0.85      0.79        33\n",
            "\n",
            "    accuracy                           0.81        81\n",
            "   macro avg       0.81      0.82      0.81        81\n",
            "weighted avg       0.82      0.81      0.82        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[38 10]\n",
            " [ 5 28]] \n",
            "\n",
            "loss: 35\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mLinear SVM\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.90      0.58      0.71        48\n",
            "    presence       0.60      0.91      0.72        33\n",
            "\n",
            "    accuracy                           0.72        81\n",
            "   macro avg       0.75      0.75      0.72        81\n",
            "weighted avg       0.78      0.72      0.71        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[28 20]\n",
            " [ 3 30]] \n",
            "\n",
            "loss: 35\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mNaive Bayes\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.86      0.75      0.80        48\n",
            "    presence       0.69      0.82      0.75        33\n",
            "\n",
            "    accuracy                           0.78        81\n",
            "   macro avg       0.77      0.78      0.78        81\n",
            "weighted avg       0.79      0.78      0.78        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[36 12]\n",
            " [ 6 27]] \n",
            "\n",
            "loss: 42\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using compination rebalacning with sample weights"
      ],
      "metadata": {
        "id": "MFCbApEskpR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['Random Forest', 'Linear SVM','Naive Bayes']\n",
        "classifiers = [RandomForestClassifier(n_estimators=100, random_state=0, class_weight={0: 15, 1: 1}), \n",
        "               SVC(kernel='linear', C=10,class_weight={0: 3, 1: 5}),\n",
        "               GaussianNB()]\n",
        "naiveBayesWeights = np.zeros(y_train_us.shape[0])\n",
        "naiveBayesWeights[np.where(y_train_us == 1)] = 13;\n",
        "naiveBayesWeights[np.where(y_train_us == 0)] = 2;"
      ],
      "metadata": {
        "id": "sUVmpxChlMML"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "  print(\"\\033[4m\" +  name + \"\\033[0m\")\n",
        "  print(\"------------------------------------------------------\")\n",
        "\n",
        "  if(name == 'Naive Bayes'):\n",
        "    clf.fit(X_train_us, y_train_us, naiveBayesWeights)\n",
        "  else:\n",
        "    clf.fit(X_train_us, y_train_us)\n",
        "    \n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  print(classification_report(y_test, y_pred, target_names=['absence','presence']))\n",
        "\n",
        "  conf_m = confusion_matrix(y_test, y_pred)\n",
        "  print(\"\\033[4m\" + \"Confusion matrix\" + \"\\033[0m\")\n",
        "  print(conf_m , \"\\n\") \n",
        "  loss = np.sum(conf_m * cost_matrix)\n",
        "  print(\"loss: %d\" %loss)\n",
        "  print(\"------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lhtUWCAkzkC",
        "outputId": "bcd44de7-07ed-4760-9c5b-3450d5ef848c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[4mRandom Forest\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.94      0.71      0.81        48\n",
            "    presence       0.69      0.94      0.79        33\n",
            "\n",
            "    accuracy                           0.80        81\n",
            "   macro avg       0.82      0.82      0.80        81\n",
            "weighted avg       0.84      0.80      0.80        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[34 14]\n",
            " [ 2 31]] \n",
            "\n",
            "loss: 24\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mLinear SVM\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.94      0.60      0.73        48\n",
            "    presence       0.62      0.94      0.75        33\n",
            "\n",
            "    accuracy                           0.74        81\n",
            "   macro avg       0.78      0.77      0.74        81\n",
            "weighted avg       0.81      0.74      0.74        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[29 19]\n",
            " [ 2 31]] \n",
            "\n",
            "loss: 29\n",
            "------------------------------------------------------\n",
            "\n",
            "\u001b[4mNaive Bayes\u001b[0m\n",
            "------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     absence       0.88      0.60      0.72        48\n",
            "    presence       0.60      0.88      0.72        33\n",
            "\n",
            "    accuracy                           0.72        81\n",
            "   macro avg       0.74      0.74      0.72        81\n",
            "weighted avg       0.77      0.72      0.72        81\n",
            "\n",
            "\u001b[4mConfusion matrix\u001b[0m\n",
            "[[29 19]\n",
            " [ 4 29]] \n",
            "\n",
            "loss: 39\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although rebalancing seems to be needless in this dataset, It seems that combining rebalancing with class weights works best for this dataset giving the best result overall."
      ],
      "metadata": {
        "id": "AEsFXJ-lsKFp"
      }
    }
  ]
}